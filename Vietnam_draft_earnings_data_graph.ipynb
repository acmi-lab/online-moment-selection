{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vietnam draft earnings data graph.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9eRkXgmvZUY"
      },
      "source": [
        "Code for generating results for the Vietnam draft and earnings data (Figure 4(c))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnF_NFvKLqRF"
      },
      "source": [
        "import numpy\n",
        "import sympy\n",
        "import pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sympy as sp\n",
        "import datetime\n",
        "import copy\n",
        "import attr\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import functools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import collections\n",
        "\n",
        "from scipy import interpolate\n",
        "from scipy import stats\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "\n",
        "HOME_DIR = \"\"\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "GhFzIvSnMWQO",
        "outputId": "727aab91-cb69-4649-95d9-a7a637d7e57c"
      },
      "source": [
        "df_angrist = pd.read_csv(os.path.join(HOME_DIR, \"angrist_1951_cohort.csv\")).drop(\"index\", axis=1)\n",
        "print(df_angrist.shape)\n",
        "col = \"earnings_normed\"\n",
        "# standardize the 'earnings` column.\n",
        "df_angrist[col] = (df_angrist[col] - np.mean(df_angrist[col])) / np.std(df_angrist[col])\n",
        "df_angrist.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2117, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   eligible  earnings_normed\n",
              "0         0         0.232759\n",
              "1         1         0.367230\n",
              "2         1         0.030211\n",
              "3         1         0.228705\n",
              "4         0         0.705876"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eligible</th>\n",
              "      <th>earnings_normed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.232759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.367230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.030211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.228705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.705876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Hku2mpMFPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf2783d-a7fa-4c68-c98f-be8844f4b0ce"
      },
      "source": [
        "class ModelParams:\n",
        "\n",
        "  def __init__(self):\n",
        "    p_z_1 = np.mean(df_angrist[\"eligible\"])\n",
        "    p_z_0 = 1 - p_z_1\n",
        "\n",
        "    # theta_1 := P(veteran|eligible=1) = 0.2831\n",
        "    # theta_0 := P(veteran|eligible=0) = 0.1468\n",
        "    theta_1 = 0.2831\n",
        "    theta_0 = 0.1468\n",
        "    \n",
        "    self.c = stats.norm.ppf(theta_0)\n",
        "    self.alpha = stats.norm.ppf(theta_1) - self.c\n",
        "\n",
        "    y_mean_eligble_1 = np.mean(df_angrist[df_angrist[\"eligible\"] == 1][\"earnings_normed\"])\n",
        "    y_mean_eligble_0 = np.mean(df_angrist[df_angrist[\"eligible\"] == 0][\"earnings_normed\"])\n",
        "    # self.beta = (y_mean_eligble_1 - y_mean_eligble_0) / (theta_1 - theta_0)\n",
        "\n",
        "    mean_veteran = theta_1 * p_z_1 + theta_0 * p_z_0\n",
        "    self.beta = np.mean(df_angrist[\"earnings_normed\"] * df_angrist[\"eligible\"]) / (theta_1*p_z_1 -  mean_veteran*p_z_1)\n",
        "    self.gamma = np.mean(df_angrist[\"earnings_normed\"]) - self.beta * mean_veteran\n",
        "\n",
        "    var_veteran = (\n",
        "        p_z_1 * p_z_0 * (theta_1 - theta_0)**2 +\n",
        "        p_z_1 * theta_1 * (1 - theta_1) + p_z_0 * theta_0 * (1 - theta_0)\n",
        "    )\n",
        "    cov_X_epsilon_x = (1 / np.sqrt(2 * np.pi)) * (np.exp(-self.c**2 / 2) * p_z_0 + np.exp(-(self.alpha + self.c)**2 / 2) * p_z_1)\n",
        "\n",
        "    self.c_x = -.5\n",
        "    self.epsilon_y_var = np.var(df_angrist[\"earnings_normed\"]) - self.beta**2 * var_veteran - self.c_x**2 - 2 * self.beta * self.c_x * cov_X_epsilon_x\n",
        "    \n",
        "  def get_true_param(self):\n",
        "    return self.beta\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"beta=%f, c_star=%f, alpha=%f, c_x=%f, epsilon_y_var=%f, gamma=%f\" % (\n",
        "        self.get_true_param(), self.c, self.alpha, self.c_x, self.epsilon_y_var, self.gamma\n",
        "    )\n",
        "    \n",
        "truth = ModelParams()\n",
        "print(truth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta=-0.431270, c_star=-1.050257, alpha=0.476600, c_x=-0.500000, epsilon_y_var=0.605823, gamma=0.083441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ki0s1tVMRqF"
      },
      "source": [
        "def generate_data_samples(num_samples, model, k=0.5):\n",
        "  np = numpy\n",
        "  pd = pandas\n",
        "\n",
        "  df_idxs = np.argmax(np.random.multinomial(1, np.ones((df_angrist.shape[0],)) / df_angrist.shape[0],\n",
        "                                            size=(num_samples,)), axis=-1)\n",
        "  eligible = df_angrist[\"eligible\"].loc[df_idxs]\n",
        "  earnings = df_angrist[\"earnings_normed\"].loc[df_idxs]\n",
        "\n",
        "  u_x = np.random.normal(size=(num_samples,))\n",
        "  # u_y = np.random.normal(scale=np.sqrt(model.epsilon_y_var / 100), size=(num_samples,))\n",
        "  u_y = np.random.normal(scale=np.sqrt(model.epsilon_y_var / 10), size=(num_samples,))\n",
        "\n",
        "  def get_Z():\n",
        "    return eligible\n",
        "  \n",
        "  def get_X(Z, u_x):\n",
        "    X_star = model.alpha * Z + model.c + u_x\n",
        "    return (X_star > 0).astype(np.float)\n",
        "  \n",
        "  def get_Y(X, u_x, u_y):\n",
        "    return model.beta * X + model.gamma + model.c_x * u_x + u_y\n",
        "  \n",
        "  Z = get_Z()\n",
        "  X = get_X(Z, u_x)\n",
        "  Y = get_Y(X, u_x, u_y)\n",
        "\n",
        "  SEL = np.zeros_like(Y, np.int32)\n",
        "  SEL[:int(SEL.shape[0] * k)] = 1\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "      \"Z\": Z,\n",
        "      \"X\": X,\n",
        "      \"Y\": Y,\n",
        "      \"SEL\": SEL\n",
        "  }).reset_index(drop=True)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "SZjPq9zcMmAv",
        "outputId": "f55a0b74-d3c2-430a-afa4-ba9e52bc7b3e"
      },
      "source": [
        "df = generate_data_samples(num_samples=10000, model=truth, k=0.5)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Z    X         Y  SEL\n",
              "0  1  0.0  0.145354    1\n",
              "1  0  0.0  0.091405    1\n",
              "2  0  0.0 -0.231617    1\n",
              "3  1  0.0  0.694866    1\n",
              "4  0  0.0 -0.420311    1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Z</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>SEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145354</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.231617</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.694866</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.420311</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNEO8xbeh5GI"
      },
      "source": [
        "class GMMEqs:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.moment_eqs, self.jacobian_eqs, self.true_param_grad, self.moment_reweighting = self._get_equations()\n",
        "  \n",
        "  def get(self):\n",
        "    return self.moment_eqs, self.jacobian_eqs, self.true_param_grad, self.moment_reweighting\n",
        "  \n",
        "  def _get_equations(self):\n",
        "    sp = sympy\n",
        "    \n",
        "    df_symbols = sp.symbols('s1, s0, S, Z, X, Y')\n",
        "    s1, s0, S, Z, X, Y = df_symbols\n",
        "    params = sp.symbols(\"y1, y0, t1, t0\")\n",
        "    y1, y0, t1, t0 = params\n",
        "\n",
        "    beta = (y1 - y0) / (t1 - t0)\n",
        "\n",
        "    # moment weights\n",
        "    m_wts = [s1, s1, s0, s0]\n",
        "    moment_reweighting = sp.zeros(len(m_wts), len(m_wts))\n",
        "    for i, mw1 in enumerate(m_wts):\n",
        "      for j, mw2 in enumerate(m_wts):\n",
        "        if mw1 == 1 or mw2 == 1:\n",
        "          moment_reweighting[i, j] = mw1 * mw2\n",
        "        elif mw1 == mw2:\n",
        "          moment_reweighting[i, j] = mw1\n",
        "\n",
        "    m1 = m_wts[0] * S * (Z * (Y - y1))\n",
        "    m2 = m_wts[1] * S * ((1-Z) * (Y - y0))\n",
        "    m3 = m_wts[2] * (1-S) * (Z*(X - t1))\n",
        "    m4 = m_wts[3] * (1-S) * ((1-Z)*(X - t0))\n",
        "\n",
        "    all_symbols = df_symbols + params\n",
        "    moments = [m1, m2, m3, m4]\n",
        "    jacobian = []\n",
        "    for mom in moments:\n",
        "      jac_row = []\n",
        "      for p in params:\n",
        "        eq = sp.simplify(sp.diff(mom, p))\n",
        "        jac_row.append(sp.lambdify(all_symbols, eq, \"numpy\"))\n",
        "      jacobian.append(jac_row)\n",
        "    \n",
        "    true_param_grad = []\n",
        "    for p in params:\n",
        "      eq = sp.simplify(sp.diff(beta, p))\n",
        "      true_param_grad.append(sp.lambdify(params, eq, \"numpy\"))\n",
        "    \n",
        "    moments = [sp.lambdify(all_symbols, eq, \"numpy\") for eq in moments]\n",
        "    moment_reweighting = sp.lambdify((s1, s0), moment_reweighting, \"numpy\")\n",
        "    return moments, jacobian, true_param_grad, moment_reweighting\n",
        "\n",
        "class GMM:\n",
        "\n",
        "  def __init__(self, df, gmm_eqs):\n",
        "    np = numpy\n",
        "\n",
        "    # self.df = df\n",
        "    self.df_dict = {k: df[k].values for k in df.columns}\n",
        "    self.df = self.df_dict\n",
        "    self.moment_eqs, self.jacobian_eqs, self.true_param_grad_eqs, self.moment_reweighting = gmm_eqs.get()\n",
        "    self.num_samples = len(df)\n",
        "    self.num_moments = len(self.moment_eqs)\n",
        "    self.momconds_arr = np.zeros((self.num_moments, self.num_samples))\n",
        "  \n",
        "  def momconds(self, params):\n",
        "    \"\"\"Returns the emprical moment vector (equivalent of \\hat{g}_n(\\theta)).\"\"\"\n",
        "    np = numpy\n",
        "\n",
        "    n = self.num_samples\n",
        "    return np.sum(self._momconds_arr(params), axis=-1) / n\n",
        "  \n",
        "  def _compute_moment_covariance(self, params):\n",
        "    \"\"\"Estimate the optimal weight matrix using the emprical moments.\"\"\"\n",
        "    n = self.num_samples\n",
        "    moms = self._momconds_arr(params)\n",
        "    moment_covariance = (moms @ moms.T) / n\n",
        "    return moment_covariance\n",
        "  \n",
        "  def _get_objective_fn(self, weight_matrix_inv):\n",
        "    \"\"\"Returns the GMM objective function.\"\"\"\n",
        "    np = numpy\n",
        "    \n",
        "    # print(weight_matrix_inv)\n",
        "    def objective(params):\n",
        "      moms = self.momconds(params)\n",
        "\n",
        "      w_inv_mom = np.linalg.solve(weight_matrix_inv, moms)\n",
        "      obj = moms.T @ w_inv_mom\n",
        "\n",
        "      return obj\n",
        "    \n",
        "    return objective\n",
        "  \n",
        "  def _momconds_arr(self, params):\n",
        "    np = numpy\n",
        "\n",
        "    p = params\n",
        "    df = self.df_dict\n",
        "    n = self.num_samples\n",
        "\n",
        "    for i, eq in enumerate(self.moment_eqs):\n",
        "      self.momconds_arr[i, :] = eq(S=df[\"SEL\"], Z=df[\"Z\"],\n",
        "                                   X=df[\"X\"], Y=df[\"Y\"],\n",
        "                                   s0=1, s1=1,\n",
        "                                   y1=p[0], y0=p[1], t1=p[2], t0=p[3])\n",
        "    \n",
        "    return self.momconds_arr\n",
        "\n",
        "  def _get_asymptotic_variance(self, k, moment_covariance, params):\n",
        "    np = numpy\n",
        "\n",
        "    current_k = np.mean(self.df[\"SEL\"])\n",
        "\n",
        "    p = params\n",
        "    df = self.df\n",
        "    n = self.num_samples\n",
        "\n",
        "    jacobian = np.zeros((self.num_moments, len(p)))\n",
        "\n",
        "    for i, jac_row in enumerate(self.jacobian_eqs):\n",
        "      for j, eq in enumerate(jac_row):\n",
        "        jacobian[i, j] = np.sum(eq(S=df[\"SEL\"], Z=df[\"Z\"],\n",
        "                                   X=df[\"X\"], Y=df[\"Y\"],\n",
        "                                   s1=k/current_k, s0=(1-k)/(1-current_k),\n",
        "                                   y1=p[0], y0=p[1], t1=p[2], t0=p[3])) / n\n",
        "\n",
        "    moment_covariance_reweight = self.moment_reweighting(s1=k/current_k, s0=(1-k)/(1-current_k))\n",
        "    \n",
        "    moment_covariance = moment_covariance * moment_covariance_reweight\n",
        "\n",
        "    mom_cov_inv_jac = np.linalg.solve(moment_covariance, jacobian)\n",
        "    variance_matrix = np.linalg.inv(jacobian.T @ mom_cov_inv_jac)\n",
        "\n",
        "    true_param_grad = np.zeros((variance_matrix.shape[0]))\n",
        "    for j, eq in enumerate(self.true_param_grad_eqs):\n",
        "      true_param_grad[j] = eq(y1=p[0], y0=p[1], t1=p[2], t0=p[3])\n",
        "    \n",
        "    return true_param_grad.T @ variance_matrix @ true_param_grad\n",
        "  \n",
        "  def get_ate_estimate(self, params):\n",
        "    return (params[0] - params[1]) / (params[2] - params[3])\n",
        "\n",
        "  def _optimize_find_parameters(self, weight_matrix_inv, initial_guess=None):\n",
        "    np = numpy\n",
        "\n",
        "    initial_guess = np.array([1, 1, 0.5, 0.5]) if initial_guess is None else initial_guess\n",
        "    res = minimize(self._get_objective_fn(weight_matrix_inv), initial_guess,\n",
        "                   bounds=[\n",
        "                           (-np.inf, np.inf),\n",
        "                           (-np.inf, np.inf),\n",
        "                           (0.01, 0.99),\n",
        "                           (0.01, 0.99),\n",
        "                   ],\n",
        "                  )\n",
        "    return res.x\n",
        "  \n",
        "  def find_parameters(self, num_iters=2, weight_matrix_reg=None):\n",
        "    np = numpy\n",
        "\n",
        "    weight_matrix_inv = np.eye(self.num_moments)\n",
        "    for i in range(num_iters):\n",
        "      params = self._optimize_find_parameters(weight_matrix_inv, initial_guess=params if i > 0 else None)\n",
        "      # print(params)\n",
        "      weight_matrix_inv = self._compute_moment_covariance(params)\n",
        "\n",
        "      if weight_matrix_reg is not None:\n",
        "        weight_matrix_inv += weight_matrix_reg * np.eye(weight_matrix_inv.shape[0])\n",
        "    \n",
        "    return params, weight_matrix_inv\n",
        "  \n",
        "  def find_optimal_k(self, moment_covariance, params):\n",
        "    np = numpy\n",
        "    \n",
        "    initial_guess = np.array([0.5])\n",
        "    lower_bound = 0.05\n",
        "    upper_bound = 0.95\n",
        "    res = minimize(lambda x: self._get_asymptotic_variance(x[0], moment_covariance, params),\n",
        "                   initial_guess, bounds=[(lower_bound, upper_bound)])\n",
        "    \n",
        "    if res.x[0] == lower_bound:\n",
        "      return 0\n",
        "    \n",
        "    if res.x[0] == upper_bound:\n",
        "      return 1\n",
        "      \n",
        "    return res.x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQB0p69BNDtx",
        "outputId": "05396e21-055d-41d3-8e07-335388494f9d"
      },
      "source": [
        "gmm = GMM(df, GMMEqs())\n",
        "params, moment_covariance = gmm.find_parameters(num_iters=2)\n",
        "\n",
        "print(\"Estimated:\")\n",
        "print(params)\n",
        "print(gmm.get_ate_estimate(params))\n",
        "print(\"True params:\")\n",
        "print(truth)\n",
        "\n",
        "optimal_k = gmm.find_optimal_k(moment_covariance, params)\n",
        "print(\"Optimal k: %f\" % optimal_k)\n",
        "\n",
        "del gmm, params, moment_covariance, optimal_k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated:\n",
            "[-0.04482065  0.03092293  0.27816271  0.1508664 ]\n",
            "-0.5950178504639706\n",
            "True params:\n",
            "beta=-0.431270, c_star=-1.050257, alpha=0.476600, c_x=-0.500000, epsilon_y_var=0.605823, gamma=0.083441\n",
            "Optimal k: 0.731171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73qVKOZ6NFf0"
      },
      "source": [
        "class SampleRevealer:\n",
        "\n",
        "  def __init__(self, budget, df):\n",
        "    self.initial_budget = budget\n",
        "    self.budget = budget\n",
        "    self.buffer_size = len(df)\n",
        "    self.df = df\n",
        "    self.counter = 0\n",
        "    self.cost_per_reveal = 1\n",
        "\n",
        "  def reset(self):\n",
        "    self.counter = 0\n",
        "    self.budget = self.initial_budget\n",
        "  \n",
        "  def is_budget_left(self, samples_to_reveal):\n",
        "    return self.budget >= (self.cost_per_reveal * samples_to_reveal)\n",
        "  \n",
        "  def reveal(self, reveal_k, samples_to_reveal):\n",
        "    if self.counter + samples_to_reveal >= self.buffer_size:\n",
        "      raise ValueError(\"no buffer\")\n",
        "    \n",
        "    observe_count = int(reveal_k * samples_to_reveal)\n",
        "    self.df[\"SEL\"].values[self.counter:self.counter+observe_count] = 1\n",
        "    self.df[\"SEL\"].values[self.counter+observe_count:self.counter+samples_to_reveal] = 0\n",
        "\n",
        "    self.counter += samples_to_reveal\n",
        "    self.budget -= (self.cost_per_reveal * samples_to_reveal)\n",
        "  \n",
        "  def get_dataset(self):\n",
        "    return self.df[:self.counter]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l65P5NrNJz_"
      },
      "source": [
        "def batch_fractions_to_sizes(horizon, batch_fractions):\n",
        "  batch_sizes = []\n",
        "    \n",
        "  for i in range(len(batch_fractions) + 1):\n",
        "    prev_batch_end = 0 if i == 0 else int(horizon * batch_fractions[i - 1])\n",
        "    curr_batch_end = horizon if i == len(batch_fractions) else int(horizon * batch_fractions[i])\n",
        "\n",
        "    batch_sizes.append(curr_batch_end - prev_batch_end)\n",
        "  \n",
        "  return batch_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ZRK516NK2h"
      },
      "source": [
        "def compute_reveal_k(current_samples, samples_to_reveal, current_k, target_k):\n",
        "  reveal_k = (target_k * (current_samples + samples_to_reveal) - current_k * current_samples) / (samples_to_reveal)\n",
        "  return min(1, (max(0, reveal_k)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV-RNHn7NLwb"
      },
      "source": [
        "class StrategyRunResult:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.budgets_used = []\n",
        "    self.squared_errors = []\n",
        "    self.optimal_ks = []\n",
        "    self.current_ks = []\n",
        "  \n",
        "  def append(self, budget_used, squared_error, optimal_k, current_k):\n",
        "    self.budgets_used.append(budget_used)\n",
        "    self.squared_errors.append(squared_error)\n",
        "    self.optimal_ks.append(optimal_k)\n",
        "    self.current_ks.append(current_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qne8L9AcNcxo"
      },
      "source": [
        "class OracleStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, gmm_equations, optimal_k, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'oracle'\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "    self.optimal_k = optimal_k\n",
        "    self.gmm_equations = gmm_equations\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset, self.gmm_equations)\n",
        "\n",
        "    self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.gmm.get_ate_estimate(self.params))**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        current_k, current_samples = 0, 0\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "      reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "\n",
        "      if i == 0:\n",
        "        df = self.sample_revealer.get_dataset()\n",
        "        if np.mean(df[\"X\"]) <= 0.1 or np.mean(df[\"Z\"]) <= 0.1:\n",
        "          return None\n",
        "\n",
        "      _ = self.get_and_store_params()\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLecabNnNfvw"
      },
      "source": [
        "class ETCStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, gmm_equations, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'etc'\n",
        "    # We assume that the first batch size is exploration.\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "    self.gmm_equations = gmm_equations\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset, self.gmm_equations)\n",
        "    self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.gmm.get_ate_estimate(self.params))**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        reveal_k = 0.5\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "        reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "\n",
        "      if i == 0:\n",
        "        df = self.sample_revealer.get_dataset()\n",
        "        if np.mean(df[\"X\"]*df[\"SEL\"]) < 0.05 or np.mean(df[\"X\"]*(1-df[\"SEL\"])) < 0.05:\n",
        "          return None\n",
        "        if np.mean(df[\"Z\"]*df[\"SEL\"]) < 0.05 or np.mean(df[\"Z\"]*(1-df[\"SEL\"])) < 0.05:\n",
        "          return None\n",
        "\n",
        "      params = self.get_and_store_params()\n",
        "\n",
        "      if i == 0:\n",
        "        self.optimal_k = self.gmm.find_optimal_k(self.moment_covariance, params)\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDWKU6BHNk3H"
      },
      "source": [
        "class ETGreedyStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, gmm_equations, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'etg'\n",
        "    # We assume that the first batch size is exploration.\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "    self.gmm_equations = gmm_equations\n",
        "    self.weight_matrix_reg = 0.01\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self, is_last_step=False):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset, self.gmm_equations)\n",
        "    if is_last_step:\n",
        "      self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    else:\n",
        "      self.params, self.moment_covariance = (\n",
        "          self.gmm.find_parameters(num_iters=2, weight_matrix_reg=self.weight_matrix_reg)\n",
        "      )\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.gmm.get_ate_estimate(self.params))**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        reveal_k = 0.5\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "        reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "      \n",
        "      if i == 0:\n",
        "        df = self.sample_revealer.get_dataset()\n",
        "        if np.mean(df[\"X\"]*df[\"SEL\"]) < 0.05 or np.mean(df[\"X\"]*(1-df[\"SEL\"])) < 0.05:\n",
        "          return None\n",
        "        if np.mean(df[\"Z\"]*df[\"SEL\"]) < 0.05 or np.mean(df[\"Z\"]*(1-df[\"SEL\"])) < 0.05:\n",
        "          return None\n",
        "\n",
        "      params = self.get_and_store_params(is_last_step=(i==len(self.batch_sizes)-1))\n",
        "\n",
        "      self.optimal_k = self.gmm.find_optimal_k(self.moment_covariance, params)\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFSUB4ohjY0X"
      },
      "source": [
        "def execute_strategy_iteration(strategy_name, iteration_num, horizon):\n",
        "  np = numpy\n",
        "\n",
        "  gmm_equations = GMMEqs()\n",
        "\n",
        "  # Uncomment the next two lines to replicate the exact runs used in the paper.\n",
        "  # random_seed = 232281293 + iteration_num\n",
        "  # np.random.seed(random_seed)\n",
        "  df = generate_data_samples(num_samples=horizon + 1000, model=truth)\n",
        "  np.random.seed(None)\n",
        "\n",
        "  sample_revealer = SampleRevealer(budget=horizon, df=df)\n",
        "\n",
        "  if strategy_name == \"etc_0.2\":\n",
        "    strategy = ETCStrategy(sample_revealer, gmm_equations=gmm_equations,\n",
        "                           horizon=horizon,\n",
        "                           batch_fractions=[0.2, 0.9])\n",
        "  elif strategy_name == \"etc_0.4\":\n",
        "    strategy = ETCStrategy(sample_revealer, gmm_equations=gmm_equations,\n",
        "                           horizon=horizon,\n",
        "                           batch_fractions=[0.4, 0.9])\n",
        "  elif strategy_name == \"oracle\":\n",
        "    strategy = OracleStrategy(sample_revealer, gmm_equations=gmm_equations, optimal_k=0.7826,\n",
        "                              horizon=horizon, batch_fractions=[0.8, 0.9])\n",
        "  elif strategy_name == \"fixed_equal\":\n",
        "    strategy = OracleStrategy(sample_revealer, gmm_equations=gmm_equations, optimal_k=0.50,\n",
        "                              horizon=horizon, batch_fractions=[0.8, 0.9])\n",
        "  elif strategy_name == \"etg_0.1\":\n",
        "    strategy = ETGreedyStrategy(sample_revealer, gmm_equations=gmm_equations,\n",
        "                        horizon=horizon,\n",
        "                        batch_fractions=[0.1, 0.2, 0.3, 0.4, 0.6, 0.8])\n",
        "  elif strategy_name == \"etg_0.2\":\n",
        "    strategy = ETGreedyStrategy(sample_revealer, gmm_equations=gmm_equations,\n",
        "                        horizon=horizon,\n",
        "                        batch_fractions=[0.2, 0.4, 0.6, 0.8])\n",
        "  else:\n",
        "    raise ValueError(\"invalid strategy_name\")\n",
        "\n",
        "  return strategy.execute_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slA3qJdUSkd-",
        "outputId": "c46fc5d5-1384-4b29-fcc4-0cca902242c3"
      },
      "source": [
        "# Test a strategy.\n",
        "\n",
        "result = execute_strategy_iteration(\"etc_0.4\", 1, horizon=1000)\n",
        "print(result.squared_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.4711640605397087, 0.11348665235017591, 0.07238505893981426]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouC-iabzSyHN"
      },
      "source": [
        "**Executing the runs for each strategy in parallel.**\n",
        "\n",
        "For the paper, we execute 12,000 runs for each strategy. We execute the runs\n",
        "in parallel using\n",
        "[`ipyparallel`](https://ipyparallel.readthedocs.io/en/latest/).\n",
        "\n",
        "The following command starts the `ipyparallel` engines:\n",
        "```\n",
        "ipcluster start -n <num_engines>\n",
        "```\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6UGhnW2SzGu"
      },
      "source": [
        "import ipyparallel as ipp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3p1yWjoS0Wm",
        "outputId": "82e30afc-aa1b-480c-88af-3bb830a5d961"
      },
      "source": [
        "# Verify that ipcluster is running and import the necessary Python packages.\n",
        "\n",
        "parallel_client = ipp.Client(debug=False)\n",
        "dview = parallel_client[:]\n",
        "# Execute an identity map in parallel.\n",
        "ar = dview.map(lambda x: x, (i for i in range(0, 2000000, 2)))\n",
        "assert ar.get()[0] == 0\n",
        "\n",
        "# Import the required Python packages.\n",
        "with dview.sync_imports():\n",
        "  from abc import ABC, abstractmethod\n",
        "  import numpy\n",
        "  import sympy\n",
        "  import pandas\n",
        "  import sympy\n",
        "  import datetime\n",
        "  import copy\n",
        "  import attr\n",
        "  import time\n",
        "  import logging\n",
        "  import itertools\n",
        "  import pickle\n",
        "  import os\n",
        "  import functools\n",
        "  import ipyparallel\n",
        "\n",
        "  import collections\n",
        "\n",
        "  from scipy.optimize import minimize\n",
        "  from scipy import interpolate\n",
        "  from scipy import stats\n",
        "  import warnings\n",
        "\n",
        "  try:\n",
        "    from cPickle import dumps, loads, HIGHEST_PROTOCOL as PICKLE_PROTOCOL\n",
        "  except ImportError:\n",
        "    from pickle import dumps, loads, HIGHEST_PROTOCOL as PICKLE_PROTOCOL\n",
        "\n",
        "# Make sure ipyparallel is still able to execute functions.\n",
        "dview = parallel_client[:]\n",
        "ar = dview.map(lambda x: x, (i for i in range(0, 2000000, 2)))\n",
        "assert ar.get()[0] == 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing ABC,abstractmethod from abc on engine(s)\n",
            "importing numpy on engine(s)\n",
            "importing sympy on engine(s)\n",
            "importing pandas on engine(s)\n",
            "importing datetime on engine(s)\n",
            "importing copy on engine(s)\n",
            "importing attr on engine(s)\n",
            "importing time on engine(s)\n",
            "importing logging on engine(s)\n",
            "importing itertools on engine(s)\n",
            "importing pickle on engine(s)\n",
            "importing os on engine(s)\n",
            "importing functools on engine(s)\n",
            "importing ipyparallel on engine(s)\n",
            "importing collections on engine(s)\n",
            "importing minimize from scipy.optimize on engine(s)\n",
            "importing interpolate from scipy on engine(s)\n",
            "importing stats from scipy on engine(s)\n",
            "importing warnings on engine(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhJpqqY-S5px"
      },
      "source": [
        "def combine_parallel_results(async_result):\n",
        "  budgets = async_result.get()[0].budgets_used\n",
        "  errors = np.vstack([res.squared_errors for res in async_result.get() if res is not None])\n",
        "  optimal_ks = np.vstack([res.optimal_ks for res in async_result.get() if res is not None])\n",
        "  current_ks = np.vstack([res.current_ks for res in async_result.get() if res is not None])\n",
        "\n",
        "  return budgets, errors, optimal_ks, current_ks\n",
        "\n",
        "def execute_strategy_in_parallel(strategy_name, horizon, iterations):\n",
        "  num_threads = len(parallel_client.ids)\n",
        "  dview = parallel_client[:]\n",
        "\n",
        "  print(\"Executing %s over %d iterations across %d cores\" % (strategy_name, iterations, num_threads))\n",
        "\n",
        "  dview[\"batch_fractions_to_sizes\"] = batch_fractions_to_sizes\n",
        "  dview[\"compute_reveal_k\"] = compute_reveal_k\n",
        "  dview[\"ModelParams\"] = ModelParams\n",
        "  dview[\"truth\"] = truth\n",
        "  dview[\"df_angrist\"] = df_angrist\n",
        "  dview[\"generate_data_samples\"] = generate_data_samples\n",
        "  dview[\"StrategyRunResult\"] = StrategyRunResult\n",
        "  dview[\"GMMEqs\"] = GMMEqs\n",
        "  dview[\"GMM\"] = GMM\n",
        "  dview[\"ETCStrategy\"] = ETCStrategy\n",
        "  dview[\"OracleStrategy\"] = OracleStrategy\n",
        "  dview[\"ETGreedyStrategy\"] = ETGreedyStrategy\n",
        "  dview[\"SampleRevealer\"] = SampleRevealer\n",
        "  dview[\"execute_strategy_iteration\"] = execute_strategy_iteration\n",
        "\n",
        "  def execute_iteration(i):\n",
        "    return execute_strategy_iteration(strategy_name, i, horizon)\n",
        "\n",
        "  return dview.map(execute_iteration, range(iterations))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKeU0GzhTB7v"
      },
      "source": [
        "def get_timeseries_for(strategy_names, horizons, iterations, results_dict):\n",
        "  results_dict[\"truth\"] = truth\n",
        "\n",
        "  for strategy_name in strategy_names:\n",
        "    for horizon in horizons:\n",
        "      print(\"Timestamp start: %s, Strategy: %s, Horizon: %d, Iters: %d\" % (\n",
        "          datetime.datetime.now(), strategy_name, horizon, iterations))\n",
        "      async_result = execute_strategy_in_parallel(strategy_name, horizon, iterations)\n",
        "      budgets, errors, optimal_ks, current_ks = combine_parallel_results(async_result)\n",
        "      print(\"Timestamp end: %s\" % (datetime.datetime.now()))\n",
        "\n",
        "      if strategy_name not in results_dict:\n",
        "        results_dict[strategy_name] = {}\n",
        "      \n",
        "      results_dict[strategy_name][horizon] = {\n",
        "          \"budgets\": budgets,\n",
        "          \"errors\": errors * budgets,\n",
        "          \"optimal_ks\": optimal_ks,\n",
        "          \"current_ks\": current_ks,\n",
        "      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw0uArdFkKtO"
      },
      "source": [
        "results_dict = {}\n",
        "get_timeseries_for([\n",
        "                    \"oracle\", \"fixed_equal\",\n",
        "                    \"etc_0.2\", \"etc_0.4\",\n",
        "                    \"etg_0.1\", \"etg_0.2\",\n",
        "                    ],\n",
        "                   horizons=[6000, 8000, 10000, 12000, 14000, 16000],\n",
        "                   iterations=12*1000,\n",
        "                   results_dict=results_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOaAsNePvpXx"
      },
      "source": [
        "# Save results to file.\n",
        "# pickle.dump(results_dict,\n",
        "#             open(os.path.join(HOME_DIR,\n",
        "#                               \"%s_veitnam_earnings_graph.pkl\" % datetime.datetime.now()),\n",
        "#                  \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msCouSwZTsLo"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqMxjsiOTSMV"
      },
      "source": [
        "# For the color map:\n",
        "# https://gist.github.com/AndiH/c957b4d769e628f506bd\n",
        "\n",
        "# Tableau 20 Colors\n",
        "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
        "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
        "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
        "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
        "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n",
        "             \n",
        "# Tableau Color Blind 10\n",
        "tableau20blind = [(0, 107, 164), (255, 128, 14), (171, 171, 171), (89, 89, 89),\n",
        "             (95, 158, 209), (200, 82, 0), (137, 137, 137), (163, 200, 236),\n",
        "             (255, 188, 121), (207, 207, 207)]\n",
        "  \n",
        "# Rescale to values between 0 and 1 \n",
        "for i in range(len(tableau20)):  \n",
        "    r, g, b = tableau20[i]  \n",
        "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
        "for i in range(len(tableau20blind)):  \n",
        "    r, g, b = tableau20blind[i]  \n",
        "    tableau20blind[i] = (r / 255., g / 255., b / 255.)\n",
        "# Use with plt.plot(…, color=tableau[0],…)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO8KzwtTOGTb"
      },
      "source": [
        "def plot_regret_curve(results_dict):\n",
        "\n",
        "  clist = rcParams['axes.prop_cycle']\n",
        "  cgen = itertools.cycle(clist)\n",
        "\n",
        "  oracle_mses = {}\n",
        "  for horizon, timeseries in results_dict[\"oracle\"].items():\n",
        "    oracle_mses[timeseries[\"budgets\"][-1]] = np.mean(timeseries[\"errors\"][:, -1])\n",
        "\n",
        "  def plot(axs, name, info, result, with_var=False):\n",
        "    x_vals = []\n",
        "    y_mean = []\n",
        "    y_std = []\n",
        "\n",
        "    current_k_mean = []\n",
        "    optimal_k_mean = []\n",
        "\n",
        "    for horizon, timeseries in result.items():\n",
        "      x_vals.append(timeseries[\"budgets\"][-1])\n",
        "\n",
        "      y_scaled = ( timeseries[\"errors\"][:, -1] - oracle_mses[x_vals[-1]] )  / oracle_mses[x_vals[-1]] * 100\n",
        "      y_mean.append(np.mean(y_scaled))\n",
        "      y_std.append(np.std(y_scaled))\n",
        "\n",
        "    x_vals = np.array(x_vals)\n",
        "    y_mean = np.array(y_mean) \n",
        "    y_std = np.array(y_std)\n",
        "\n",
        "    x_sort_idx = np.argsort(x_vals)\n",
        "    x_vals = x_vals[x_sort_idx]\n",
        "    y_mean = y_mean[x_sort_idx]\n",
        "    y_std = y_std[x_sort_idx]\n",
        "    \n",
        "    color = next(cgen)[\"color\"]\n",
        "\n",
        "    plt.plot(x_vals, y_mean, label=name, color=info[1], linestyle=info[0],  marker=info[2])\n",
        "    plt.legend()\n",
        "\n",
        "    if with_var:\n",
        "      ci = 1.96 * y_std / np.sqrt(timeseries[\"errors\"].shape[0])\n",
        "      axs.errorbar(x_vals, y_mean, yerr=ci, ls=\"none\", color=info[1])\n",
        "      \n",
        "  name_to_linestyle_color = {\n",
        "      \"etc_0.2\": [\"dashdot\", tableau20blind[1], \"s\"],\n",
        "      \"etc_0.4\": [\"solid\", tableau20blind[2], \"v\"],\n",
        "      \"etg_0.1\": [\"dotted\", tableau20blind[4], \"^\"],\n",
        "      \"etg_0.2\": [\"dashed\", tableau20blind[6], \"D\"],\n",
        "      \"fixed_equal\": [\"solid\", tableau20blind[8], \">\"],\n",
        "  }\n",
        "  plt.title(\"Relative regret vs horizon\")\n",
        "  plt.xlabel(\"Total samples collected (Horizon)\")\n",
        "  plt.ylabel(\"Relative regret (%)\")\n",
        "  for name, info in name_to_linestyle_color.items():  \n",
        "    plot(plt, name, info, results_dict[name], with_var=True)\n",
        "  \n",
        "  # plt.savefig(os.path.join(HOME_DIR, \"figures/vietnam_draft_earnings_regret_curve.eps\"), bbox_inches='tight', pad_inches=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyfXX1IKOSkg"
      },
      "source": [
        "plot_regret_curve(results_dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
