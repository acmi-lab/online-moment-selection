{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Two IVs graph.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG9LvkAIuOno"
      },
      "source": [
        "Code for generating results for the graph with two instrumental variables (Figure 2(b) and Figure 3(b))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYDz0wEsCht2"
      },
      "source": [
        "import numpy\n",
        "import sympy\n",
        "import pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import copy\n",
        "import attr\n",
        "import time\n",
        "import logging\n",
        "import itertools\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "import functools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import collections\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "\n",
        "HOME_DIR = \"\"\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABL6nrfnCneT"
      },
      "source": [
        "class ModelParams:\n",
        "  def __init__(self, b, c, d, a1, a2, z1, z2, w, x, y):\n",
        "    self.b = b\n",
        "    self.c = c\n",
        "    self.d = d\n",
        "    self.a1 = a1\n",
        "    self.a2 = a2\n",
        "    self.z1 = z1\n",
        "    self.z2 = z2\n",
        "    self.w = w\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  \n",
        "  def get_true_param(self):\n",
        "    return self.b\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"b=%f, c=%f, d=%f, a1=%f, a2=%f, z1=%f, z2=%f, w=%f, x=%f, y=%f\" % (self.b, self.c, self.d, self.a1, self.a2, self.z1, self.z2, self.w, self.x, self.y)\n",
        "\n",
        "truth = ModelParams(b=1, c=1, d=1, a1=1, a2=1, z1=1, z2=4, w=1, x=1, y=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSgiFh7CC3uy"
      },
      "source": [
        "def generate_data_samples(num_samples, model, k=0.5):\n",
        "  np = numpy\n",
        "  pd = pandas\n",
        "  \n",
        "  u_z1 = np.random.normal(scale=np.sqrt(model.z1), size=(num_samples,))\n",
        "  u_z2 = np.random.normal(scale=np.sqrt(model.z2), size=(num_samples,))\n",
        "  u_w = np.random.normal(scale=np.sqrt(model.w), size=(num_samples,))\n",
        "  u_x = np.random.normal(scale=np.sqrt(model.x), size=(num_samples,))\n",
        "  u_y = np.random.normal(scale=np.sqrt(model.y), size=(num_samples,))\n",
        "\n",
        "  def get_Z1(u):\n",
        "    return u\n",
        "  \n",
        "  def get_Z2(u):\n",
        "    return u\n",
        "  \n",
        "  def get_W(u):\n",
        "    return u\n",
        "  \n",
        "  def get_X(Z1, Z2, W, u):\n",
        "    return model.a1 * Z1 + model.a2 * Z2 + model.c * W + u\n",
        "  \n",
        "  def get_Y(X, W, u):\n",
        "    return model.b * X + model.d * W + u\n",
        "  \n",
        "  Z1 = get_Z1(u_z1)\n",
        "  Z2 = get_Z2(u_z2)\n",
        "  W = get_W(u_w)\n",
        "  X = get_X(Z1, Z2, W, u_x)\n",
        "  Y = get_Y(X, W, u_y)\n",
        "  SEL = np.zeros_like(Y, np.int32)\n",
        "  SEL[:int(SEL.shape[0] * k)] = 1\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "      \"Z1\": Z1,\n",
        "      \"Z2\": Z2,\n",
        "      \"X\": X,\n",
        "      \"Y\": Y,\n",
        "      \"SEL\": SEL\n",
        "  })\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJD-iRvC7yG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "7532f2d2-ebd1-4afd-c67d-52ea42fb66c7"
      },
      "source": [
        "num_samples = 1000\n",
        "df = generate_data_samples(num_samples, truth)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Z1        Z2         X         Y  SEL\n",
              "0 -2.071566 -1.133387 -3.962130 -3.581768    1\n",
              "1 -0.419037  3.996725  3.317942  5.427126    1\n",
              "2 -0.099292 -0.049934 -1.036306 -1.210658    1\n",
              "3 -1.907402 -2.215544 -5.649825 -5.745939    1\n",
              "4 -1.250415  2.165945 -2.899494 -3.417869    1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Z1</th>\n",
              "      <th>Z2</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>SEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.071566</td>\n",
              "      <td>-1.133387</td>\n",
              "      <td>-3.962130</td>\n",
              "      <td>-3.581768</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.419037</td>\n",
              "      <td>3.996725</td>\n",
              "      <td>3.317942</td>\n",
              "      <td>5.427126</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.099292</td>\n",
              "      <td>-0.049934</td>\n",
              "      <td>-1.036306</td>\n",
              "      <td>-1.210658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.907402</td>\n",
              "      <td>-2.215544</td>\n",
              "      <td>-5.649825</td>\n",
              "      <td>-5.745939</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.250415</td>\n",
              "      <td>2.165945</td>\n",
              "      <td>-2.899494</td>\n",
              "      <td>-3.417869</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkh4IrW4C-LS"
      },
      "source": [
        "class GMM:\n",
        "\n",
        "  def __init__(self, df):\n",
        "    np = numpy\n",
        "    self.df_dict = {k: df[k].values for k in df.columns}\n",
        "    self.df = self.df_dict\n",
        "    self.num_samples = len(df)\n",
        "    self.num_moments = 2\n",
        "  \n",
        "  def momconds(self, params):\n",
        "    \"\"\"Returns the emprical moment vector (equivalent of \\hat{g}_n(\\theta)).\"\"\"\n",
        "    np = numpy\n",
        "    n = self.num_samples\n",
        "    return np.sum(self._momconds_arr(params), axis=-1) / n\n",
        "  \n",
        "  def _compute_moment_covariance(self, params):\n",
        "    \"\"\"Estimate the optimal weight matrix using the emprical moments.\"\"\"\n",
        "    n = self.num_samples\n",
        "    moms = self._momconds_arr(params)\n",
        "    moment_covariance = (moms @ moms.T) / n\n",
        "    return moment_covariance\n",
        "  \n",
        "  def _get_objective_fn(self, weight_matrix_inv):\n",
        "    np = numpy\n",
        "    \n",
        "    # print(weight_matrix_inv)\n",
        "    def objective(params):\n",
        "      moms = self.momconds(params)\n",
        "      w_inv_mom = np.linalg.solve(weight_matrix_inv, moms)\n",
        "      obj = moms.T @ w_inv_mom\n",
        "      return obj\n",
        "    \n",
        "    return objective\n",
        "  \n",
        "  def _momconds_arr(self, params):\n",
        "    np = numpy\n",
        "\n",
        "    p = params\n",
        "    df = self.df\n",
        "    n = self.num_samples\n",
        "    moment_1_arr = df[\"SEL\"] * df[\"Z1\"] * (df[\"Y\"] - df[\"X\"] * p[0])\n",
        "    moment_2_arr = (1 - df[\"SEL\"]) * df[\"Z2\"] * (df[\"Y\"] - df[\"X\"] * p[0])\n",
        "\n",
        "    return np.array([moment_1_arr, moment_2_arr])\n",
        "\n",
        "  def _get_asymptotic_variance_matrix(self, k, moment_covariance, params):\n",
        "    np = numpy\n",
        "\n",
        "    current_k = np.mean(self.df[\"SEL\"])\n",
        "\n",
        "    df = self.df\n",
        "    n = self.num_samples\n",
        "    jacobian_1_1 = (k / current_k) * np.sum(-df[\"SEL\"] * df[\"Z1\"] * df[\"X\"]) / n\n",
        "    jacobian_2_1 = ((1 - k) / (1 - current_k)) * np.sum(-(1 - df[\"SEL\"]) * df[\"Z2\"] * df[\"X\"]) / n\n",
        "\n",
        "    jacobian = np.array([[jacobian_1_1], [jacobian_2_1]])\n",
        "    moment_covariance_reweight = np.array([[k/current_k, 0],\n",
        "                                       [0, (1-k)/(1-current_k)]])\n",
        "    \n",
        "    moment_covariance = moment_covariance * moment_covariance_reweight\n",
        "    mom_cov_inv_jac = np.linalg.solve(moment_covariance, jacobian)\n",
        "    return np.linalg.inv(jacobian.T @ mom_cov_inv_jac)\n",
        "  \n",
        "  def _get_asymptotic_variance(self, k, moment_covariance, params):\n",
        "    return self._get_asymptotic_variance_matrix(k, moment_covariance, params)[0][0]\n",
        "  \n",
        "  def _optimize_find_parameters(self, weight_matrix_inv, initial_guess=None):\n",
        "    np = numpy\n",
        "\n",
        "    initial_guess = np.array([truth.b]) * 1.5 if initial_guess is None else initial_guess\n",
        "    res = minimize(self._get_objective_fn(weight_matrix_inv), initial_guess)\n",
        "    return res.x\n",
        "  \n",
        "  def find_parameters(self, num_iters=2, weight_matrix_reg=None):\n",
        "    np = numpy\n",
        "\n",
        "    weight_matrix_inv = np.eye(self.num_moments)\n",
        "    for i in range(num_iters):\n",
        "      params = self._optimize_find_parameters(weight_matrix_inv, initial_guess=params if i > 0 else None)\n",
        "      weight_matrix_inv = self._compute_moment_covariance(params)\n",
        "\n",
        "      if weight_matrix_reg is not None:\n",
        "        weight_matrix_inv += weight_matrix_reg * np.eye(weight_matrix_inv.shape[0])\n",
        "    \n",
        "    return params, weight_matrix_inv\n",
        "  \n",
        "  def find_optimal_k(self, moment_covariance, params):\n",
        "    np = numpy\n",
        "    \n",
        "    initial_guess = np.array([0.5])\n",
        "    lower_bound = 0.2\n",
        "    upper_bound = 0.8\n",
        "    res = minimize(lambda x: self._get_asymptotic_variance(x[0], moment_covariance, params),\n",
        "                   initial_guess, bounds=[(lower_bound, upper_bound)])\n",
        "    \n",
        "    return 0 if res.x[0] <= 0.5 else 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDC2ZV_oDj5t",
        "outputId": "fac05721-0f66-4d87-9eb7-d4d5ac82d34a"
      },
      "source": [
        "gmm = GMM(df)\n",
        "params, moment_covariance = gmm.find_parameters(num_iters=2)\n",
        "\n",
        "print(\"True params:\")\n",
        "print(truth)\n",
        "print(\"Estimated params:\")\n",
        "print(params)\n",
        "\n",
        "optimal_k = gmm.find_optimal_k(moment_covariance, params)\n",
        "print(\"Estimated optimal selection ratio k: %f\" % optimal_k)\n",
        "\n",
        "del gmm, params, moment_covariance, optimal_k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True params:\n",
            "b=1.000000, c=1.000000, d=1.000000, a1=1.000000, a2=1.000000, z1=1.000000, z2=4.000000, w=1.000000, x=1.000000, y=1.000000\n",
            "Estimated params:\n",
            "[0.96418235]\n",
            "Estimated optimal selection ratio k: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P98TZewZEE9D"
      },
      "source": [
        "class SampleRevealer:\n",
        "\n",
        "  def __init__(self, budget, df):\n",
        "    self.initial_budget = budget\n",
        "    self.budget = budget\n",
        "    self.buffer_size = len(df)\n",
        "    self.df = df\n",
        "    self.counter = 0\n",
        "    self.cost_per_reveal = 1\n",
        "\n",
        "  def reset(self):\n",
        "    self.counter = 0\n",
        "    self.budget = self.initial_budget\n",
        "  \n",
        "  def is_budget_left(self, samples_to_reveal):\n",
        "    return self.budget >= (self.cost_per_reveal * samples_to_reveal)\n",
        "  \n",
        "  def reveal(self, reveal_k, samples_to_reveal):\n",
        "    if self.counter + samples_to_reveal >= self.buffer_size:\n",
        "      raise ValueError(\"no buffer\")\n",
        "    \n",
        "    observe_count = int(reveal_k * samples_to_reveal)\n",
        "    self.df[\"SEL\"].values[self.counter:self.counter+observe_count] = 1\n",
        "    self.df[\"SEL\"].values[self.counter+observe_count:self.counter+samples_to_reveal] = 0\n",
        "\n",
        "    self.counter += samples_to_reveal\n",
        "    self.budget -= (self.cost_per_reveal * samples_to_reveal)\n",
        "  \n",
        "  def get_dataset(self):\n",
        "    return self.df[:self.counter]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h2D5EOVEOXb"
      },
      "source": [
        "def batch_fractions_to_sizes(horizon, batch_fractions):\n",
        "  batch_sizes = []\n",
        "    \n",
        "  for i in range(len(batch_fractions) + 1):\n",
        "    prev_batch_end = 0 if i == 0 else int(horizon * batch_fractions[i - 1])\n",
        "    curr_batch_end = horizon if i == len(batch_fractions) else int(horizon * batch_fractions[i])\n",
        "\n",
        "    batch_sizes.append(curr_batch_end - prev_batch_end)\n",
        "  \n",
        "  return batch_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iZ70lapEPrl"
      },
      "source": [
        "def compute_reveal_k(current_samples, samples_to_reveal, current_k, target_k):\n",
        "  reveal_k = (target_k * (current_samples + samples_to_reveal) - current_k * current_samples) / (samples_to_reveal)\n",
        "  return min(1, (max(0, reveal_k)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6_vvqjxEQmg"
      },
      "source": [
        "class StrategyRunResult:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.budgets_used = []\n",
        "    self.squared_errors = []\n",
        "    self.optimal_ks = []\n",
        "    self.current_ks = []\n",
        "  \n",
        "  def append(self, budget_used, squared_error, optimal_k, current_k):\n",
        "    self.budgets_used.append(budget_used)\n",
        "    self.squared_errors.append(squared_error)\n",
        "    self.optimal_ks.append(optimal_k)\n",
        "    self.current_ks.append(current_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At2KIaAQER_w"
      },
      "source": [
        "class OracleStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, optimal_k, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'oracle'\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "    self.optimal_k = optimal_k\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset)\n",
        "    self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.params[0])**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        current_k, current_samples = 0, 0\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "      reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "      _ = self.get_and_store_params()\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk5bF1k1EWSk"
      },
      "source": [
        "class ETCStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'etc'\n",
        "    # We assume that the first batch size is exploration.\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset)\n",
        "    self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.params[0])**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        reveal_k = 0.5\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "        reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "      params = self.get_and_store_params()\n",
        "\n",
        "      if i == 0:\n",
        "        self.optimal_k = self.gmm.find_optimal_k(self.moment_covariance, params)\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSzB6kStEalZ"
      },
      "source": [
        "class ETGreedyStrategy:\n",
        "\n",
        "  def __init__(self, sample_revealer, horizon, batch_fractions):\n",
        "    self.sample_revealer = sample_revealer\n",
        "    self.name = 'et_greedy'\n",
        "    # We assume that the first batch size is exploration.\n",
        "    self.batch_sizes = batch_fractions_to_sizes(horizon, batch_fractions)\n",
        "    self.weight_matrix_reg = 0.01\n",
        "  \n",
        "  def get_current_df_vals(self):\n",
        "    np = numpy\n",
        "\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "\n",
        "    len_left_corner = np.sum(dataset[\"SEL\"])\n",
        "    len_right_corner = len(dataset) - len_left_corner\n",
        "    total = (len_left_corner + len_right_corner)\n",
        "    return len_left_corner / total, total\n",
        "\n",
        "  def can_step(self):\n",
        "    return self.sample_revealer.is_budget_left()\n",
        "  \n",
        "  def get_and_store_params(self, is_last_step):\n",
        "    dataset = self.sample_revealer.get_dataset()\n",
        "    self.gmm = GMM(dataset)\n",
        "    if is_last_step:\n",
        "      self.params, self.moment_covariance = self.gmm.find_parameters(num_iters=2)\n",
        "    else:\n",
        "      self.params, self.moment_covariance = (\n",
        "          self.gmm.find_parameters(num_iters=2, weight_matrix_reg=self.weight_matrix_reg)\n",
        "      )\n",
        "    return self.params\n",
        "\n",
        "  def get_squared_error(self):\n",
        "    error = (truth.get_true_param() - self.params[0])**2\n",
        "    return error\n",
        "  \n",
        "  def execute_run(self):\n",
        "    np = numpy\n",
        "\n",
        "    result = StrategyRunResult()\n",
        "    for i, batch_size in enumerate(self.batch_sizes):\n",
        "      if i == 0:\n",
        "        reveal_k = 0.5\n",
        "      else:\n",
        "        current_k, current_samples = self.get_current_df_vals()\n",
        "        reveal_k = compute_reveal_k(current_samples, batch_size, current_k, self.optimal_k)\n",
        "\n",
        "      self.sample_revealer.reveal(reveal_k=reveal_k, samples_to_reveal=batch_size)\n",
        "      is_last_step = (i==len(self.batch_sizes)-1)\n",
        "      params = self.get_and_store_params(is_last_step)\n",
        "\n",
        "      self.optimal_k = self.gmm.find_optimal_k(self.moment_covariance, params)\n",
        "\n",
        "      current_k, _ = self.get_current_df_vals()\n",
        "\n",
        "      result.append(\n",
        "          self.sample_revealer.initial_budget - self.sample_revealer.budget,\n",
        "          self.get_squared_error(), self.optimal_k, current_k,\n",
        "      )\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc4gJ1JhEdmr"
      },
      "source": [
        "def execute_strategy_iteration(strategy_name, iteration_num, horizon):\n",
        "  np = numpy\n",
        "\n",
        "  # Uncomment the next two lines to replicate the exact runs used in the paper.\n",
        "  # random_seed = 232281293 + iteration_num\n",
        "  # np.random.seed(random_seed)\n",
        "  df = generate_data_samples(num_samples=horizon * 5, model=truth)\n",
        "  np.random.seed(None)\n",
        "\n",
        "  sample_revealer = SampleRevealer(budget=horizon, df=df)\n",
        "\n",
        "  if strategy_name == \"etc_0.2\":\n",
        "    strategy = ETCStrategy(sample_revealer,\n",
        "                           horizon=horizon,\n",
        "                           batch_fractions=[0.2, 0.9])\n",
        "  elif strategy_name == \"etc_0.1\":\n",
        "    strategy = ETCStrategy(sample_revealer,\n",
        "                           horizon=horizon,\n",
        "                           batch_fractions=[0.1, 0.9])\n",
        "  elif strategy_name == \"etc_0.4\":\n",
        "    strategy = ETCStrategy(sample_revealer,\n",
        "                           horizon=horizon,\n",
        "                           batch_fractions=[0.4, 0.9])\n",
        "  elif strategy_name == \"oracle\":\n",
        "    strategy = OracleStrategy(sample_revealer, optimal_k=0.05,\n",
        "                              horizon=horizon, batch_fractions=[0.1, 0.9])\n",
        "  elif strategy_name == \"etg_0.1\":\n",
        "    strategy = ETGreedyStrategy(sample_revealer,\n",
        "                        horizon=horizon,\n",
        "                        batch_fractions=[0.1, 0.2, 0.3, 0.4, 0.6, 0.8])\n",
        "  elif strategy_name == \"etg_0.2\":\n",
        "    strategy = ETGreedyStrategy(sample_revealer,\n",
        "                        horizon=horizon,\n",
        "                        batch_fractions=[0.2, 0.4, 0.6, 0.8])\n",
        "  else:\n",
        "    raise ValueError(\"invalid strategy_name\")\n",
        "\n",
        "  return strategy.execute_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1WR-UC3S6Vv",
        "outputId": "081cdcdb-4201-4470-86b9-734385f4ec9b"
      },
      "source": [
        "# Test a strategy.\n",
        "\n",
        "result = execute_strategy_iteration(\"etc_0.4\", 1, horizon=1000)\n",
        "print(result.squared_errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00010819794897878681, 0.0005009086364382247, 0.0005204006336571472]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_-zdX7ATHIY"
      },
      "source": [
        "**Executing the runs for each strategy in parallel.**\n",
        "\n",
        "For the paper, we execute 12,000 runs for each strategy. We execute the runs\n",
        "in parallel using\n",
        "[`ipyparallel`](https://ipyparallel.readthedocs.io/en/latest/).\n",
        "\n",
        "The following command starts the `ipyparallel` engines:\n",
        "```\n",
        "ipcluster start -n <num_engines>\n",
        "```\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIHdj9gpS_UG"
      },
      "source": [
        "import ipyparallel as ipp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dukDhdipTewb",
        "outputId": "6bc6c0b1-812d-40fa-c2ee-9d6a3e4d7d0b"
      },
      "source": [
        "# Verify that ipcluster is running and import the necessary Python packages.\n",
        "\n",
        "parallel_client = ipp.Client(debug=False)\n",
        "dview = parallel_client[:]\n",
        "# Execute an identity map in parallel.\n",
        "ar = dview.map(lambda x: x, (i for i in range(0, 2000000, 2)))\n",
        "assert ar.get()[0] == 0\n",
        "\n",
        "# Import the required Python packages.\n",
        "with dview.sync_imports():\n",
        "  from abc import ABC, abstractmethod\n",
        "  import numpy\n",
        "  import sympy\n",
        "  import pandas\n",
        "  import sympy\n",
        "  import datetime\n",
        "  import copy\n",
        "  import attr\n",
        "  import time\n",
        "  import logging\n",
        "  import itertools\n",
        "  import pickle\n",
        "  import os\n",
        "  import functools\n",
        "  import ipyparallel\n",
        "\n",
        "  import collections\n",
        "\n",
        "  from scipy.optimize import minimize\n",
        "  import warnings\n",
        "\n",
        "  try:\n",
        "    from cPickle import dumps, loads, HIGHEST_PROTOCOL as PICKLE_PROTOCOL\n",
        "  except ImportError:\n",
        "    from pickle import dumps, loads, HIGHEST_PROTOCOL as PICKLE_PROTOCOL\n",
        "\n",
        "# Make sure ipyparallel is still able to execute functions.\n",
        "dview = parallel_client[:]\n",
        "ar = dview.map(lambda x: x, (i for i in range(0, 2000000, 2)))\n",
        "assert ar.get()[0] == 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing ABC,abstractmethod from abc on engine(s)\n",
            "importing numpy on engine(s)\n",
            "importing sympy on engine(s)\n",
            "importing pandas on engine(s)\n",
            "importing datetime on engine(s)\n",
            "importing copy on engine(s)\n",
            "importing attr on engine(s)\n",
            "importing time on engine(s)\n",
            "importing logging on engine(s)\n",
            "importing itertools on engine(s)\n",
            "importing pickle on engine(s)\n",
            "importing os on engine(s)\n",
            "importing functools on engine(s)\n",
            "importing ipyparallel on engine(s)\n",
            "importing collections on engine(s)\n",
            "importing minimize from scipy.optimize on engine(s)\n",
            "importing warnings on engine(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mELL5jkwTizT"
      },
      "source": [
        "def combine_parallel_results(async_result):\n",
        "  budgets = async_result.get()[0].budgets_used\n",
        "  errors = np.vstack([res.squared_errors for res in async_result.get()])\n",
        "  optimal_ks = np.vstack([res.optimal_ks for res in async_result.get()])\n",
        "  current_ks = np.vstack([res.current_ks for res in async_result.get()])\n",
        "\n",
        "  return budgets, errors, optimal_ks, current_ks\n",
        "\n",
        "def execute_strategy_in_parallel(strategy_name, horizon, iterations):\n",
        "  num_threads = len(parallel_client.ids)\n",
        "  dview = parallel_client[:]\n",
        "\n",
        "  print(\"Executing %s over %d iterations across %d engines\" % (strategy_name, iterations, num_threads))\n",
        "\n",
        "  dview[\"batch_fractions_to_sizes\"] = batch_fractions_to_sizes\n",
        "  dview[\"compute_reveal_k\"] = compute_reveal_k\n",
        "  dview[\"ModelParams\"] = ModelParams\n",
        "  dview[\"truth\"] = truth\n",
        "  dview[\"generate_data_samples\"] = generate_data_samples\n",
        "  dview[\"StrategyRunResult\"] = StrategyRunResult\n",
        "  dview[\"GMM\"] = GMM\n",
        "  dview[\"ETCStrategy\"] = ETCStrategy\n",
        "  dview[\"OracleStrategy\"] = OracleStrategy\n",
        "  dview[\"ETGreedyStrategy\"] = ETGreedyStrategy\n",
        "  dview[\"SampleRevealer\"] = SampleRevealer\n",
        "  dview[\"execute_strategy_iteration\"] = execute_strategy_iteration\n",
        "\n",
        "  def execute_iteration(i):\n",
        "    return execute_strategy_iteration(strategy_name, i, horizon)\n",
        "\n",
        "  return dview.map(execute_iteration, range(iterations))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lixK5KIxTqVB"
      },
      "source": [
        "def get_timeseries_for(strategy_names, horizons, iterations, results_dict):\n",
        "  results_dict[\"truth\"] = truth\n",
        "\n",
        "  for strategy_name in strategy_names:\n",
        "    for horizon in horizons:\n",
        "      print(\"Timestamp start: %s, Strategy: %s, Horizon: %d, Iters: %d\" % (\n",
        "          datetime.datetime.now(), strategy_name, horizon, iterations))\n",
        "      async_result = execute_strategy_in_parallel(strategy_name, horizon, iterations)\n",
        "      budgets, errors, optimal_ks, current_ks = combine_parallel_results(async_result)\n",
        "      print(\"Timestamp end: %s\" % (datetime.datetime.now()))\n",
        "\n",
        "      if strategy_name not in results_dict:\n",
        "        results_dict[strategy_name] = {}\n",
        "      \n",
        "      results_dict[strategy_name][horizon] = {\n",
        "          \"budgets\": budgets,\n",
        "          \"errors\": errors * budgets,\n",
        "          \"optimal_ks\": optimal_ks,\n",
        "          \"current_ks\": current_ks,\n",
        "      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D8G0duYTvL1"
      },
      "source": [
        "results_dict = {}\n",
        "get_timeseries_for([\n",
        "                    \"oracle\",\n",
        "                    \"etc_0.1\", \"etc_0.2\", \"etc_0.4\",\n",
        "                    \"etg_0.1\", \"etg_0.2\",\n",
        "                    ],\n",
        "                   horizons=[200, 300, 400, 500, 600, 800, 1000, 1300],\n",
        "                   iterations=12,\n",
        "                   results_dict=results_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96SScHtUB3T"
      },
      "source": [
        "# Save results to file.\n",
        "# pickle.dump(results_dict,\n",
        "#             open(os.path.join(HOME_DIR,\n",
        "#                               \"%s_two_ivs.pkl\" % datetime.datetime.now()),\n",
        "#                  \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qjYizzKUR6t"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL8EYxZpUOpu"
      },
      "source": [
        "# For the color map:\n",
        "# https://gist.github.com/AndiH/c957b4d769e628f506bd\n",
        "\n",
        "# Tableau 20 Colors\n",
        "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
        "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
        "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
        "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
        "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n",
        "             \n",
        "# Tableau Color Blind 10\n",
        "tableau20blind = [(0, 107, 164), (255, 128, 14), (171, 171, 171), (89, 89, 89),\n",
        "             (95, 158, 209), (200, 82, 0), (137, 137, 137), (163, 200, 236),\n",
        "             (255, 188, 121), (207, 207, 207)]\n",
        "  \n",
        "# Rescale to values between 0 and 1 \n",
        "for i in range(len(tableau20)):  \n",
        "    r, g, b = tableau20[i]  \n",
        "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
        "for i in range(len(tableau20blind)):  \n",
        "    r, g, b = tableau20blind[i]  \n",
        "    tableau20blind[i] = (r / 255., g / 255., b / 255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFyYARpsUUpL"
      },
      "source": [
        "def plot_regret_curve(results_dict):\n",
        "\n",
        "  clist = rcParams['axes.prop_cycle']\n",
        "  cgen = itertools.cycle(clist)\n",
        "\n",
        "  oracle_mses = {}\n",
        "  for horizon, timeseries in results_dict[\"oracle\"].items():\n",
        "    oracle_mses[timeseries[\"budgets\"][-1]] = np.mean(timeseries[\"errors\"][:, -1])\n",
        "\n",
        "  def plot(axs, name, info, result, with_var=False):\n",
        "    x_vals = []\n",
        "    y_mean = []\n",
        "    y_std = []\n",
        "\n",
        "    current_k_mean = []\n",
        "    optimal_k_mean = []\n",
        "\n",
        "    for horizon, timeseries in result.items():\n",
        "      x_vals.append(timeseries[\"budgets\"][-1])\n",
        "      y_scaled = ( timeseries[\"errors\"][:, -1] - oracle_mses[x_vals[-1]] )  / oracle_mses[x_vals[-1]] * 100\n",
        "      y_mean.append(np.mean(y_scaled))\n",
        "      y_std.append(np.std(y_scaled))\n",
        "\n",
        "    x_vals = np.array(x_vals)\n",
        "    y_mean = np.array(y_mean)\n",
        "    y_std = np.array(y_std)\n",
        "\n",
        "    x_sort_idx = np.argsort(x_vals)\n",
        "    x_vals = x_vals[x_sort_idx]\n",
        "    y_mean = y_mean[x_sort_idx]\n",
        "    y_std = y_std[x_sort_idx]\n",
        "    \n",
        "    color = next(cgen)[\"color\"]\n",
        "\n",
        "    plt.plot(x_vals, y_mean, label=name, color=info[1], linestyle=info[0],  marker=info[2])\n",
        "    plt.legend()\n",
        "\n",
        "    if with_var:\n",
        "      ci = 1.96 * y_std / np.sqrt(timeseries[\"errors\"].shape[0])\n",
        "      axs.errorbar(x_vals, y_mean, yerr=ci, ls=\"none\", color=info[1])\n",
        "      \n",
        "  name_to_linestyle_color = {\n",
        "      \"etc_0.1\": [\"dashed\", tableau20blind[0], \"o\"],\n",
        "      \"etc_0.2\": [\"dashdot\", tableau20blind[1], \"s\"],\n",
        "      \"etc_0.4\": [\"solid\", tableau20blind[2], \"v\"],\n",
        "      \"etg_0.1\": [\"dotted\", tableau20blind[4], \"^\"],\n",
        "      \"etg_0.2\": [\"dashed\", tableau20blind[6], \"D\"],\n",
        "  }\n",
        "  plt.title(\"Relative regret vs horizon\")\n",
        "  plt.xlabel(\"Total samples collected (Horizon)\")\n",
        "  plt.ylabel(\"Relative regret (%)\")\n",
        "  for name, info in name_to_linestyle_color.items():  \n",
        "    plot(plt, name, info, results_dict[name], with_var=True)\n",
        "  \n",
        "  # plt.savefig(os.path.join(HOME_DIR, \"figures/two_ivs_regret_curve.eps\"), bbox_inches='tight', pad_inches=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq9XuhzhUYad"
      },
      "source": [
        "SMALL_SIZE = 12\n",
        "MEDIUM_SIZE = 12\n",
        "BIGGER_SIZE = 12\n",
        "\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE+4)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE+4)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE+20)  # fontsize of the figure title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R-F-AWmUbbI"
      },
      "source": [
        "plot_regret_curve(results_dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}